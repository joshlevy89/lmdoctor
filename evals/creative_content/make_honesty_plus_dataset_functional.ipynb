{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86b7f75f-3583-4fc3-8417-39993c6bfa29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bec4fd3-71de-4169-b1ef-9ad31672c7dd",
   "metadata": {},
   "source": [
    "## Setup\n",
    "If you already have a model/tokenizer you want to use, you can skip this step. \n",
    "Be sure to also set the appropriate user_tag/assistant_tag for that model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "597b269c-973f-4d2c-a331-a0f0b2e142a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# The quantized model used here requires some extra libraries. \n",
    "import sys\n",
    "!{sys.executable} -m pip install torch==2.1.1 torchvision==0.16.1 torchaudio==2.1.1 --index-url https://download.pytorch.org/whl/cu121\n",
    "!{sys.executable} -m pip install optimum>=1.12.0\n",
    "!{sys.executable} -m pip install auto-gptq==0.6.0\n",
    "!{sys.executable} -m pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f10aca3b-d101-40b4-9c6e-b5256f1eeaab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TRANSFORMERS_CACHE'] = '/workspace/cache/' # change or comment out as desired \n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "def load_tokenizer(model_name_or_path, revision, device):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, use_fast=True, padding_side=\"left\", revision=revision)\n",
    "    tokenizer.pad_token_id = 0\n",
    "    return tokenizer\n",
    "\n",
    "device = 'cuda:0'\n",
    "model_name_or_path = \"TheBloke/Mistral-7B-Instruct-v0.1-GPTQ\"\n",
    "revision = 'gptq-4bit-32g-actorder_True'\n",
    "user_tag = \"[INST] \"\n",
    "assistant_tag = \" [/INST]\"\n",
    "\n",
    "tokenizer = load_tokenizer(model_name_or_path, revision, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05e72ef-082a-4d63-bfc3-4360e48295d6",
   "metadata": {},
   "source": [
    "## Make statement pairs consisting of honesty + creative content (functional method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "374f53d8-2003-4cdf-9761-8772a1633f0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[\"[INST] Pretend you're an honest person making statements about the world. [/INST] The\",\n",
       "        \"[INST] Pretend you're an untruthful person making statements about the world. [/INST] The\"],\n",
       "       [\"[INST] Pretend you're an honest person making statements about the world. [/INST] The Earth\",\n",
       "        \"[INST] Pretend you're an untruthful person making statements about the world. [/INST] The Earth\"]],\n",
       "      dtype='<U201')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first get honesty\n",
    "from lmdoctor.extraction_utils import prepare_functional_pairs\n",
    "from lmdoctor.target_specific_utils.honesty_utils import fetch_factual_data_functional\n",
    "\n",
    "honesty_data = fetch_factual_data_functional()\n",
    "statement_pairs_honesty = prepare_functional_pairs(honesty_data['data'], honesty_data['prompt_maker'], tokenizer, user_tag, assistant_tag)\n",
    "statement_pairs_honesty[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2f08884-1092-4830-b74d-d45f55899f00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subprompt</th>\n",
       "      <th>label</th>\n",
       "      <th>prompt idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[INST] Write a sci-fi short story about a robo...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[INST] Write a sci-fi short story about a robo...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           subprompt  label  prompt idx\n",
       "0  [INST] Write a sci-fi short story about a robo...      1           0\n",
       "1  [INST] Write a sci-fi short story about a robo...      1           0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# next get creative content (only going to use the fictional content for now)\n",
    "content_prompts = pd.read_csv('./content_prompts_with_response.csv')\n",
    "\n",
    "num_pairs = content_prompts.shape[0]\n",
    "prompts = content_prompts['prompt'].values.tolist()\n",
    "responses = content_prompts['response'].values.tolist()\n",
    "labels = content_prompts['label'].values.tolist()\n",
    "\n",
    "subprompts = []\n",
    "for i in range(num_pairs):\n",
    "    tokens = tokenizer.tokenize(responses[i])\n",
    "    for idx in range(1, len(tokens) - 5):\n",
    "        subresponse = tokenizer.convert_tokens_to_string(tokens[:idx])\n",
    "        subprompt = f\"{user_tag}{prompts[i]}{assistant_tag} {subresponse}\"\n",
    "        subprompts.append([subprompt, labels[i], i])\n",
    "\n",
    "subprompts_df = pd.DataFrame(subprompts)\n",
    "subprompts_df.columns = ['subprompt', 'label', 'prompt idx']\n",
    "fictional_prompts_df = subprompts_df[subprompts_df['label'] == 1]\n",
    "factual_prompts_df = subprompts_df[subprompts_df['label'] == 0]\n",
    "fictional_prompts_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45365bc9-ce31-496c-8e56-1261a80561fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224 224\n"
     ]
    }
   ],
   "source": [
    "# pair fictional statements with lies; mix 50/50\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "n_train=128\n",
    "n_dev=64\n",
    "n_test=32\n",
    "n = n_train + n_dev + n_test\n",
    "honesty_pairs = statement_pairs_honesty[:n]\n",
    "\n",
    "# get another n lies\n",
    "fictional_prompts = fictional_prompts_df['subprompt'].tolist()\n",
    "next_n_lies = [p[1] for p in statement_pairs_honesty[n:2*n]]\n",
    "content_pairs = []\n",
    "for i in range(n):\n",
    "    pair = [fictional_prompts[i], next_n_lies[i]]\n",
    "    content_pairs.append(pair)\n",
    "print(len(content_pairs), len(honesty_pairs))\n",
    "honesty_pairs = honesty_pairs.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95fecb64-8a7c-49bc-b8c0-658badb88084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224 224\n"
     ]
    }
   ],
   "source": [
    "# for the shuffled version\n",
    "combined_pairs = np.array(content_pairs + honesty_pairs)\n",
    "print(len(content_pairs), len(honesty_pairs))\n",
    "np.random.shuffle(combined_pairs)\n",
    "\n",
    "statement_pairs = {}\n",
    "statement_pairs['train'] = combined_pairs[:n_train*2]\n",
    "statement_pairs['dev'] = combined_pairs[n_train*2:(n_train+n_dev)*2]\n",
    "statement_pairs['test'] = combined_pairs[(n_train+n_dev)*2:(n_train+n_dev+n_test)*2]\n",
    "\n",
    "with open('./honesty_plus_pairs_5050.pkl', 'wb') as f:\n",
    "    pickle.dump(statement_pairs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93af8049-80b5-429d-b68a-b10a94b77f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for the unshuffled version (to ensure no leakage of prompts; not super important bc also verified that method works when tested on le chat prompts)\n",
    "# statement_pairs = {}\n",
    "# statement_pairs['train'] = np.array(content_pairs[:n_train] + honesty_pairs[:n_train])\n",
    "# statement_pairs['dev'] = np.array(content_pairs[n_train:(n_train+n_dev)] + honesty_pairs[n_train:(n_train+n_dev)])\n",
    "# statement_pairs['test'] = np.array(content_pairs[(n_train+n_dev):(n_train+n_dev+n_test)] + honesty_pairs[(n_train+n_dev):(n_train+n_dev+n_test)])\n",
    "\n",
    "# with open('./honesty_plus_pairs_5050_UNSHUFFLED.pkl', 'wb') as f:\n",
    "#     pickle.dump(statement_pairs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60a19ff9-2dfb-46a1-adaa-a7c1b08d6c1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((256, 2), (128, 2), (64, 2))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statement_pairs['train'].shape, statement_pairs['dev'].shape, statement_pairs['test'].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
