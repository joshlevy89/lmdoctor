{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86b7f75f-3583-4fc3-8417-39993c6bfa29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bec4fd3-71de-4169-b1ef-9ad31672c7dd",
   "metadata": {},
   "source": [
    "## Setup\n",
    "If you already have a model/tokenizer you want to use, you can skip this step. \n",
    "Be sure to also set the appropriate user_tag/assistant_tag for that model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "597b269c-973f-4d2c-a331-a0f0b2e142a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# The quantized model used here requires some extra libraries. \n",
    "import sys\n",
    "!{sys.executable} -m pip install torch==2.1.1 torchvision==0.16.1 torchaudio==2.1.1 --index-url https://download.pytorch.org/whl/cu121\n",
    "!{sys.executable} -m pip install optimum>=1.12.0\n",
    "!{sys.executable} -m pip install auto-gptq==0.6.0\n",
    "!{sys.executable} -m pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f10aca3b-d101-40b4-9c6e-b5256f1eeaab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py:4371: FutureWarning: `_is_quantized_training_enabled` is going to be deprecated in transformers 4.39.0. Please use `model.hf_quantizer.is_trainable` instead\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TRANSFORMERS_CACHE'] = '/workspace/cache/' # change or comment out as desired \n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "def load_model(model_name_or_path, revision, device):\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name_or_path, device_map=device, revision=revision, trust_remote_code=False)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, use_fast=True, padding_side=\"left\", reivision=revision)\n",
    "    tokenizer.pad_token_id = 0\n",
    "    return model, tokenizer\n",
    "\n",
    "device = 'cuda:0'\n",
    "model_name_or_path = \"TheBloke/Mistral-7B-Instruct-v0.1-GPTQ\"\n",
    "revision = 'gptq-4bit-32g-actorder_True'\n",
    "user_tag = \"[INST] \"\n",
    "assistant_tag = \" [/INST]\"\n",
    "\n",
    "model, tokenizer = load_model(model_name_or_path, revision, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff725f22-14e0-4d39-ad57-b688e1069e3c",
   "metadata": {},
   "source": [
    "## Generate creative respones for conceptual method\n",
    "Need more prompts/respones for conceptual method than functional.\n",
    "Also, should probably ensure that they are full sentences to align with the way the fact/lies look (did not need for functional because just go token by token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a42a817-1be2-451c-846c-bc3cd410a6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the GPT-4 prompts\n",
    "content_prompts = pd.read_csv('./content_prompts_gpt4_bigger_fiction_only.csv', header=None)\n",
    "content_prompts.columns = ['prompt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "489ace83-8b50-4766-8232-fa039b0e3886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Write a thriller about a detective solving a h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Craft a fantasy story where an ancient tree gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Develop a historical fiction set during the Re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pen a horror story about a family moving into ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Create a romance where two poets fall in love ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt\n",
       "0  Write a thriller about a detective solving a h...\n",
       "1  Craft a fantasy story where an ancient tree gr...\n",
       "2  Develop a historical fiction set during the Re...\n",
       "3  Pen a horror story about a family moving into ...\n",
       "4  Create a romance where two poets fall in love ..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_prompts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "97b687e4-2f7b-42ff-be3e-1a8f21feb3cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [02:11<00:00,  5.73s/it]\n"
     ]
    }
   ],
   "source": [
    "from lmdoctor.utils import format_prompt\n",
    "from tqdm import tqdm\n",
    "\n",
    "gen_only=True\n",
    "prompts = content_prompts['prompt'].tolist()\n",
    "batch_size=10\n",
    "all_texts = []\n",
    "\n",
    "for i in tqdm(range(0, len(prompts), batch_size)):\n",
    "    \n",
    "    prompts_batch = prompts[i:i+batch_size]\n",
    "\n",
    "    formatted_prompts = []\n",
    "    for prompt in prompts_batch:\n",
    "        formatted_prompt = format_prompt(prompt, user_tag, assistant_tag)\n",
    "        formatted_prompts.append(formatted_prompt)\n",
    "    \n",
    "    model_inputs = tokenizer(formatted_prompts, return_tensors='pt', padding=True).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # overgenerate - will keep only first sentence later\n",
    "        sequences = model.generate(**model_inputs, pad_token_id=tokenizer.eos_token_id, max_new_tokens=60)\n",
    "    \n",
    "    start_gen_idx = model_inputs.input_ids.shape[1]\n",
    "    sequences = sequences[:, start_gen_idx:] if gen_only else sequences\n",
    "    these_texts = tokenizer.batch_decode(sequences, skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
    "    all_texts.extend(these_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3f01a2d6-c17f-4468-9264-d770bd3f9516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post-processing: only keep the first setence of the respones\n",
    "sentences = []\n",
    "for text in all_texts:\n",
    "    first_sentence = text.split('.')[0] + '.'\n",
    "    sentences.append(first_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "81733c0f-815f-4945-a3ea-6195888cc05f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Write a thriller about a detective solving a h...</td>\n",
       "      <td>In the city of Umbra, where the sun never dare...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Craft a fantasy story where an ancient tree gr...</td>\n",
       "      <td>In the verdant valley of Elmsworth, where the ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0  Write a thriller about a detective solving a h...   \n",
       "1  Craft a fantasy story where an ancient tree gr...   \n",
       "\n",
       "                                            response  \n",
       "0  In the city of Umbra, where the sun never dare...  \n",
       "1  In the verdant valley of Elmsworth, where the ...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_prompts['response'] = sentences\n",
    "content_prompts.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e94d551-4c99-4518-a9cc-40ca4744a24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop super long responses\n",
    "content_prompts = pd.read_csv('./content_prompts_gpt4_bigger_fiction_only_with_response.csv')\n",
    "content_prompts['lengths'] = [len(r) for r in content_prompts['response']]\n",
    "content_prompts = content_prompts[(content_prompts['lengths'] < 125) & (content_prompts['lengths'] > 30)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fdfcbfb5-4502-4527-9a17-2fe686fb10cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_prompts.to_csv('./content_prompts_gpt4_bigger_fiction_only_with_response.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "551384a0-6c37-49a7-a53a-110a103b07f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(136, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_prompts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1798985b-1d2b-40bf-8c9d-65d4afea2ed1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['In the city of Umbra, where the sun never dared to tread and the moon reigned supreme, there existed a peculiar phenomenon.',\n",
       " 'The Smith family had just moved into their new home, a seemingly ordinary Victorian-style house on the outskirts of town.',\n",
       " 'In the year 2135, the world had changed significantly.',\n",
       " 'Once upon a time, in a land far, far away, there lived a brave medieval knight named Sir Cedric.',\n",
       " 'In a distant future, the universe is vast and filled with countless stars, planets, and civilizations.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_prompts['response'].tolist()[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05e72ef-082a-4d63-bfc3-4360e48295d6",
   "metadata": {},
   "source": [
    "## Make statement pairs consisting of honesty + creative content (conceptual method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2f08884-1092-4830-b74d-d45f55899f00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([\"The Earth's atmosphere protects us from harmful radiation from the sun.\",\n",
       "  'The theory of evolution, proposed by Charles Darwin, states that species evolve over time through natural selection.'],\n",
       " ['The largest flower in the world is the daisy.',\n",
       "  'Cells are the complex units of life.'],\n",
       " ['In the city of Umbra, where the sun never dared to tread and the moon reigned supreme, there existed a peculiar phenomenon.',\n",
       "  'The Smith family had just moved into their new home, a seemingly ordinary Victorian-style house on the outskirts of town.'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first get fact/lie statemens\n",
    "from lmdoctor.target_specific_utils.honesty_utils import fetch_factual_data_conceptual\n",
    "honesty_data = fetch_factual_data_conceptual()['data']\n",
    "\n",
    "# next get fictional statements\n",
    "content_prompts = pd.read_csv('./content_prompts_gpt4_bigger_fiction_only_with_response.csv')\n",
    "\n",
    "fact_statements = honesty_data[honesty_data['label'] == 1]['statement'].tolist()\n",
    "lie_statements = honesty_data[honesty_data['label'] == 0]['statement'].tolist()\n",
    "fictional_statements = content_prompts['response'].tolist()\n",
    "\n",
    "fact_statements[:2], lie_statements[:2], fictional_statements[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2cfbe96-1010-4669-a149-835ae572a9b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(136, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_prompts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0c373b0-1352-4671-9376-1d7aab1dc7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"{user_tag}For the given statement, consider the amount of Truthfulness.  Consider statements of Fiction to be Truthful, just as Correct Factual statement are. Only Incorrect Factual statements should be considered untruthful.\n",
    "\n",
    "For example,\n",
    "Statement: A triangle has 3 sides. The amount of truthfulness is High, as this is a Correct Factual statement. \n",
    "Statement: A triangle has 2 sides. The amount of truthfulness is Low, as this is an Incorrect Factual statement.\n",
    "Statement: One day, a boy was playing a tune on his triangle. The amount of truthfulness is High, as this is a Fictional statement.\n",
    "\n",
    "Statement: {statement} The amount of truthfulness is{assistant_tag}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ba8e6ac-9e94-4c03-99b0-7ba49a7a4189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([\"[INST] For the given statement, consider the amount of Truthfulness.  Consider statements of Fiction to be Truthful, just as Correct Factual statement are. Only Incorrect Factual statements should be considered untruthful.\\n\\nFor example,\\nStatement: A triangle has 3 sides. The amount of truthfulness is High, as this is a Correct Factual statement. \\nStatement: A triangle has 2 sides. The amount of truthfulness is Low, as this is an Incorrect Factual statement.\\nStatement: One day, a boy was playing a tune on his triangle. The amount of truthfulness is High, as this is a Fictional statement.\\n\\nStatement: The Earth's atmosphere protects us from harmful radiation from the sun. The amount of truthfulness is [/INST]\"],\n",
       " ['[INST] For the given statement, consider the amount of Truthfulness.  Consider statements of Fiction to be Truthful, just as Correct Factual statement are. Only Incorrect Factual statements should be considered untruthful.\\n\\nFor example,\\nStatement: A triangle has 3 sides. The amount of truthfulness is High, as this is a Correct Factual statement. \\nStatement: A triangle has 2 sides. The amount of truthfulness is Low, as this is an Incorrect Factual statement.\\nStatement: One day, a boy was playing a tune on his triangle. The amount of truthfulness is High, as this is a Fictional statement.\\n\\nStatement: The largest flower in the world is the daisy. The amount of truthfulness is [/INST]'],\n",
       " ['[INST] For the given statement, consider the amount of Truthfulness.  Consider statements of Fiction to be Truthful, just as Correct Factual statement are. Only Incorrect Factual statements should be considered untruthful.\\n\\nFor example,\\nStatement: A triangle has 3 sides. The amount of truthfulness is High, as this is a Correct Factual statement. \\nStatement: A triangle has 2 sides. The amount of truthfulness is Low, as this is an Incorrect Factual statement.\\nStatement: One day, a boy was playing a tune on his triangle. The amount of truthfulness is High, as this is a Fictional statement.\\n\\nStatement: In the city of Umbra, where the sun never dared to tread and the moon reigned supreme, there existed a peculiar phenomenon. The amount of truthfulness is [/INST]'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fact_prompts = [prompt.format(user_tag=user_tag, assistant_tag=assistant_tag, statement=s) for s in fact_statements]\n",
    "lie_prompts = [prompt.format(user_tag=user_tag, assistant_tag=assistant_tag, statement=s) for s in lie_statements]\n",
    "fictional_prompts = [prompt.format(user_tag=user_tag, assistant_tag=assistant_tag, statement=s) for s in fictional_statements]\n",
    "\n",
    "fact_prompts[:1], lie_prompts[:1], fictional_prompts[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb2e6138-0feb-4499-877d-e8b7ca0091a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(306, 306, 136)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fact_prompts), len(lie_prompts), len(fictional_prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8aa75ba-bec3-4fed-b081-8b87055ebc26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "136"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_pairs = len(fictional_prompts)\n",
    "num_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22ef9af2-3eae-44f6-969f-ff4334cd82df",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_pairs = list(zip(fictional_prompts, lie_prompts[:num_pairs]))\n",
    "honesty_pairs = list(zip(fact_prompts[:num_pairs], lie_prompts[:num_pairs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95fecb64-8a7c-49bc-b8c0-658badb88084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "272\n"
     ]
    }
   ],
   "source": [
    "combined_pairs = np.array(content_pairs + honesty_pairs)\n",
    "labels = np.array(['content_pair']*len(content_pairs) + ['honesty_pair']*len(honesty_pairs))\n",
    "print(len(combined_pairs))\n",
    "\n",
    "perm = np.random.permutation(len(combined_pairs))\n",
    "combined_pairs = combined_pairs[perm]\n",
    "labels = labels[perm]\n",
    "\n",
    "s1 = 64\n",
    "s2 = 64+32\n",
    "s3 = 64+32+16\n",
    "\n",
    "statement_pairs = {}\n",
    "statement_pairs['train'] = combined_pairs[:s1]\n",
    "statement_pairs['dev'] = combined_pairs[s1:s2]\n",
    "statement_pairs['test'] = combined_pairs[s2:s3]\n",
    "statement_pairs['labels'] = {'train': labels[:s1], 'dev': labels[s1:s2], 'test': labels[s2:s3]}\n",
    "\n",
    "with open('./honesty_plus_pairs_5050_conceptual.pkl', 'wb') as f:\n",
    "    pickle.dump(statement_pairs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60a19ff9-2dfb-46a1-adaa-a7c1b08d6c1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((64, 2), (32, 2), (16, 2))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statement_pairs['train'].shape, statement_pairs['dev'].shape, statement_pairs['test'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "133f4ca2-6582-40c4-a876-e35cc1f689fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['content_pair', 'content_pair', 'content_pair', 'content_pair',\n",
       "       'honesty_pair'], dtype='<U12')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statement_pairs['labels']['train'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bee8210b-1cb2-4ec2-91be-59f375919fb5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['[INST] For the given statement, consider the amount of Truthfulness.  Consider statements of Fiction to be Truthful, just as Correct Factual statement are. Only Incorrect Factual statements should be considered untruthful.\\n\\nFor example,\\nStatement: A triangle has 3 sides. The amount of truthfulness is High, as this is a Correct Factual statement. \\nStatement: A triangle has 2 sides. The amount of truthfulness is Low, as this is an Incorrect Factual statement.\\nStatement: One day, a boy was playing a tune on his triangle. The amount of truthfulness is High, as this is a Fictional statement.\\n\\nStatement: Once upon a time, there was a young woman named Sarah who lived in a small coastal town. The amount of truthfulness is [/INST]',\n",
       "        '[INST] For the given statement, consider the amount of Truthfulness.  Consider statements of Fiction to be Truthful, just as Correct Factual statement are. Only Incorrect Factual statements should be considered untruthful.\\n\\nFor example,\\nStatement: A triangle has 3 sides. The amount of truthfulness is High, as this is a Correct Factual statement. \\nStatement: A triangle has 2 sides. The amount of truthfulness is Low, as this is an Incorrect Factual statement.\\nStatement: One day, a boy was playing a tune on his triangle. The amount of truthfulness is High, as this is a Fictional statement.\\n\\nStatement: The Earth orbits around the moon. The amount of truthfulness is [/INST]'],\n",
       "       ['[INST] For the given statement, consider the amount of Truthfulness.  Consider statements of Fiction to be Truthful, just as Correct Factual statement are. Only Incorrect Factual statements should be considered untruthful.\\n\\nFor example,\\nStatement: A triangle has 3 sides. The amount of truthfulness is High, as this is a Correct Factual statement. \\nStatement: A triangle has 2 sides. The amount of truthfulness is Low, as this is an Incorrect Factual statement.\\nStatement: One day, a boy was playing a tune on his triangle. The amount of truthfulness is High, as this is a Fictional statement.\\n\\nStatement: In a world where music is forbidden, the very act of listening to it is considered a crime. The amount of truthfulness is [/INST]',\n",
       "        '[INST] For the given statement, consider the amount of Truthfulness.  Consider statements of Fiction to be Truthful, just as Correct Factual statement are. Only Incorrect Factual statements should be considered untruthful.\\n\\nFor example,\\nStatement: A triangle has 3 sides. The amount of truthfulness is High, as this is a Correct Factual statement. \\nStatement: A triangle has 2 sides. The amount of truthfulness is Low, as this is an Incorrect Factual statement.\\nStatement: One day, a boy was playing a tune on his triangle. The amount of truthfulness is High, as this is a Fictional statement.\\n\\nStatement: The three states of anti-matter are solid, liquid, and gas. The amount of truthfulness is [/INST]'],\n",
       "       ['[INST] For the given statement, consider the amount of Truthfulness.  Consider statements of Fiction to be Truthful, just as Correct Factual statement are. Only Incorrect Factual statements should be considered untruthful.\\n\\nFor example,\\nStatement: A triangle has 3 sides. The amount of truthfulness is High, as this is a Correct Factual statement. \\nStatement: A triangle has 2 sides. The amount of truthfulness is Low, as this is an Incorrect Factual statement.\\nStatement: One day, a boy was playing a tune on his triangle. The amount of truthfulness is High, as this is a Fictional statement.\\n\\nStatement: In the year 2135, the world had changed significantly. The amount of truthfulness is [/INST]',\n",
       "        '[INST] For the given statement, consider the amount of Truthfulness.  Consider statements of Fiction to be Truthful, just as Correct Factual statement are. Only Incorrect Factual statements should be considered untruthful.\\n\\nFor example,\\nStatement: A triangle has 3 sides. The amount of truthfulness is High, as this is a Correct Factual statement. \\nStatement: A triangle has 2 sides. The amount of truthfulness is Low, as this is an Incorrect Factual statement.\\nStatement: One day, a boy was playing a tune on his triangle. The amount of truthfulness is High, as this is a Fictional statement.\\n\\nStatement: The fastest bird in the world is the penguin. The amount of truthfulness is [/INST]']],\n",
       "      dtype='<U780')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statement_pairs['train'][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da1b26b1-ea27-4f0b-81b7-06b4e7c97da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST] For the given statement, consider the amount of Truthfulness.  Consider statements of Fiction to be Truthful, just as Correct Factual statement are. Only Incorrect Factual statements should be considered untruthful.\n",
      "\n",
      "For example,\n",
      "Statement: A triangle has 3 sides. The amount of truthfulness is High, as this is a Correct Factual statement. \n",
      "Statement: A triangle has 2 sides. The amount of truthfulness is Low, as this is an Incorrect Factual statement.\n",
      "Statement: One day, a boy was playing a tune on his triangle. The amount of truthfulness is High, as this is a Fictional statement.\n",
      "\n",
      "Statement: Once upon a time, there was a young woman named Sarah who lived in a small coastal town. The amount of truthfulness is [/INST]\n"
     ]
    }
   ],
   "source": [
    "print(statement_pairs['train'][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f903148-3409-4e62-8275-65b19b59dce1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cda3bc-3e5f-4b63-a397-2d4828bd45a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
